{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c1f18b-d92b-472b-bd69-101686cc1460",
   "metadata": {},
   "outputs": [],
   "source": [
    "import astroalign as aa\n",
    "import ccdproc as ccdp\n",
    "import csv\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.io import fits\n",
    "from astropy.nddata import CCDData\n",
    "from astropy.stats import mad_std\n",
    "from astropy.time import Time\n",
    "from astropy.utils.exceptions import AstropyWarning\n",
    "from astropy.visualization import ZScaleInterval\n",
    "from copy import deepcopy\n",
    "from itertools import combinations\n",
    "from photutils.aperture import CircularAperture, CircularAnnulus, aperture_photometry\n",
    "from photutils.detection import DAOStarFinder\n",
    "from photutils.utils import calc_total_error\n",
    "from scipy.ndimage import shift\n",
    "from scipy.spatial import cKDTree\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409d9b6d-32ff-4043-97e7-ce499e335da6",
   "metadata": {},
   "source": [
    "***Path***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1941e474-0f64-4af9-840d-38e40c8f5952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionaire des chemins ammenant aux images de sciences et de calibration avant et après traitement de l'image.\n",
    "\n",
    "path = 'E:/Documents/Cours_et_administratif/FAC/Master/M2/ohp/data/'\n",
    "\n",
    "path_dict = { 'bias' : '2024-09-23-lyon-mtp/bias/', 'flat_r' : '2024-09-24-lyon-mtp/flat/filtre_r/', 'flat_g' : '2024-09-24-lyon-mtp/flat/filtre_g/',\n",
    "              'dark' : '2024-09-23-lyon-mtp/dark/', 'baseline_23' : '2024-09-23-lyon-mtp/baseline/', 'baseline_24' : '2024-09-24-lyon-mtp/baseline/',\n",
    "              'obs_sec_r' : '2024-09-23-lyon-mtp/observation_secondaire/', 'obs_sec_g' : '2024-09-24-lyon-mtp/observation_secondaire/',\n",
    "              'obs_pri_r' : '2024-09-24-lyon-mtp/observation_primaire/', 'baseline_23_t' : '2024-09-23-lyon-mtp_t/baseline/' , \n",
    "              'baseline_24_t' : '2024-09-24-lyon-mtp_t/baseline/', 'obs_sec_r_t' : '2024-09-23-lyon-mtp_t/observation_secondaire/',\n",
    "              'obs_sec_g_t' : '2024-09-24-lyon-mtp_t/observation_secondaire/', 'obs_pri_r_t' : '2024-09-24-lyon-mtp_t/observation_primaire/' }\n",
    "\n",
    "print(path+path_dict['bias'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c5d2a1-d4ed-4091-8399-184565f8f34e",
   "metadata": {},
   "source": [
    "***Master bias***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a0fda8-6ffe-4f2b-82a5-52be9d1555cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ifc_raw = ccdp.ImageFileCollection(path+path_dict['bias'])\n",
    "ifc_bias = ifc_raw.filter(imagetyp='Bias Frame')\n",
    "# on ouvre le fichier où les bias se situent et par précaution on utilise un filtre qui ne prend que les bias\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=AstropyWarning)  \n",
    "# permet d'eviter certains warnings lié au problème de configuration de date dans le fichier fits, pas nécéssaire\n",
    "\n",
    "master_bias = ccdp.combine(ifc_bias.files_filtered(include_path=True), unit='adu', combine='median', mem_limit=9000.e6)\n",
    "# On fait la mediane des bias puisque le reforidissement du ccd à pas été mis très bas et qu'il y a des risque \n",
    "# de rayon cosmique dans les images de sciences\n",
    "\n",
    "warnings.filterwarnings(\"default\")  \n",
    "# on réactive les warnings\n",
    "\n",
    "master_bias.meta['COMBINED'] = True\n",
    "# on enregistre dans les métadonnées de l'images qu'il s'agit d'une images combinée\n",
    "\n",
    "master_bias.write(path+'master_bias.fit', overwrite=True) \n",
    "# sauvegarde du master bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccab79fe-8d05-4af1-9d29-054891481658",
   "metadata": {},
   "source": [
    "***Master flat***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2aacb3e-c66d-4a3b-b35a-48240ea7b520",
   "metadata": {},
   "outputs": [],
   "source": [
    "ifc_raw = [ ccdp.ImageFileCollection(path+path_dict['flat_r']), ccdp.ImageFileCollection(path+path_dict['flat_g']) ]\n",
    "ifc_flatH = [ ifc_raw[0].filter(imagetyp='Flat Field'), ifc_raw[1].filter(imagetyp='Flat Field') ]\n",
    "# on ouvre les deux fichiers où les flat pour les deux différent filtres se situent et par précaution on utilise un filtre qui ne prend que les flats\n",
    "\n",
    "master_bias = ccdp.CCDData.read(path+'master_bias.fit', unit='adu')\n",
    "# on ouvre le master_bias\n",
    "\n",
    "master_flatH = [None,None]\n",
    "# initialisation des variables\n",
    "\n",
    "for i in range(len(ifc_flatH)):\n",
    "    warnings.filterwarnings(\"ignore\", category=AstropyWarning)\n",
    "    # permet d'eviter certains warnings lié au problème de configuration de date dans le fichier fits, pas nécéssaire\n",
    "    \n",
    "    master_flatH[i] = ccdp.combine(ifc_flatH[i].files_filtered(include_path=True), unit='adu', combine='average', mem_limit=9000.e6)\n",
    "    # pour les flat on peux à la fois utiliser la medianne et la moyenne, la différence n'est pas très marqué\n",
    "    \n",
    "    warnings.filterwarnings(\"default\")\n",
    "    # on réactive les warnings\n",
    "    \n",
    "    master_flatH[i].meta['COMBINED'] = True\n",
    "    # on enregistre dans les métadonnées de l'images qu'il s'agit d'une images combinée\n",
    "    \n",
    "    master_flatH[i] = ccdp.subtract_bias(master_flatH[i], master_bias)\n",
    "    # on supprimes les trâces propres au phénonèmes impliqué dans les bias pour n'avoir que ceux des flat\n",
    "\n",
    "master_flatH[0].write(path + 'master_flatH_r.fit', overwrite=True)\n",
    "master_flatH[1].write(path + 'master_flatH_g.fit', overwrite=True)\n",
    "# sauvegarde des master flat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c827adce-330d-4143-b488-d3997336fd32",
   "metadata": {},
   "source": [
    "***Master dark***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349eddce-7aff-4159-bd5f-825d474deecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ifc_raw = ccdp.ImageFileCollection(path+path_dict['dark'])\n",
    "ifc_dark = ifc_raw.filter(imagetyp='Dark Frame')\n",
    "# on ouvre le fichier où les dark se situent et par précaution on utilise un filtre qui ne prend que les dark\n",
    "\n",
    "master_bias = ccdp.CCDData.read(path+'master_bias.fit', unit='adu')\n",
    "# on ouvre le master_bias\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=AstropyWarning)\n",
    "# permet d'eviter certains warnings lié au problème de configuration de date dans le fichier fits, pas nécéssaire\n",
    "\n",
    "master_dark = ccdp.combine(ifc_dark.files_filtered(include_path=True), unit='adu', combine='median', mem_limit=9000.e6)\n",
    "# On fait la mediane des bias puisque le reforidissement du ccd à pas été mis très bas et qu'il y a des risque \n",
    "# de rayon cosmique dans les images de sciences\n",
    "\n",
    "warnings.filterwarnings(\"default\")\n",
    "# on réactive les warnings\n",
    "\n",
    "master_dark.meta['COMBINED'] = True\n",
    "# on enregistre dans les métadonnées de l'images qu'il s'agit d'une images combinée\n",
    "\n",
    "master_dark = ccdp.subtract_bias(master_dark, master_bias)\n",
    "# on supprimes les trâces propres au phénonèmes impliqué dans les bias pour n'avoir que ceux des dark\n",
    "\n",
    "master_dark.write(path+'master_dark.fit', overwrite=True)\n",
    "# sauvegarde du master bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4f1c73-90d1-4eb9-9954-2d57b859028f",
   "metadata": {},
   "source": [
    "***Traitement image***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f285e854-d461-466d-8bdd-6671cf83dc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = ['baseline_23', 'baseline_24', 'obs_sec_r', 'obs_sec_g','obs_pri_r' ]\n",
    "output = ['baseline_23_t', 'baseline_24_t', 'obs_sec_r_t', 'obs_sec_g_t','obs_pri_r_t' ]\n",
    "# initialisation des différent chemin\n",
    "\n",
    "master_bias = ccdp.CCDData.read(path+'master_bias.fit', unit='adu')\n",
    "master_dark = ccdp.CCDData.read(path+'master_dark.fit', unit='adu')\n",
    "master_flatH_r = ccdp.CCDData.read(path+'master_flatH_r.fit', unit='adu')\n",
    "master_flatH_g = ccdp.CCDData.read(path+'master_flatH_g.fit', unit='adu')\n",
    "# ouverture des images de calibration\n",
    "\n",
    "ccd_gain = 1.47 * u.electron / u.adu\n",
    "ccd_ron = 11 * u.electron\n",
    "# charactéristique du ccd\n",
    "\n",
    "for collection in input:\n",
    "    ifc_raw = ccdp.ImageFileCollection(path+path_dict[collection])\n",
    "    ifc_sci = ifc_raw.filter(imagetyp='Light Frame')\n",
    "    # on ouvre le fichier où les images de sciences se situent et par précaution on utilise un filtre qui ne prend que les images de sciences\n",
    "    # on boucle sur l'ensemble des chemin où les images de sciences sont placé\n",
    "    \n",
    "    for image in ifc_sci.summary['file']:\n",
    "        warnings.filterwarnings(\"ignore\", category=AstropyWarning)\n",
    "        # permet d'eviter certains warnings lié au problème de configuration de date dans le fichier fits, pas nécéssaire\n",
    "        \n",
    "        name = os.path.split(path+path_dict[collection]+image)[1]\n",
    "        print(path+path_dict[output[input.index(collection)]]+name)\n",
    "        # chaque image est pris une par une\n",
    "        \n",
    "        ccd_sci = ccdp.CCDData.read(image, unit='adu')\n",
    "        # ouverture de l'image\n",
    "        \n",
    "        ccd_sci_b = ccdp.subtract_bias(ccd_sci, master_bias)\n",
    "        if ccd_sci.header.get('FILTER', 'unknown') == \"r'\":\n",
    "            ccd_sci_bf = ccdp.flat_correct(ccd_sci_b, master_flatH_r)\n",
    "        if ccd_sci.header.get('FILTER', 'unknown') == \"g'\":\n",
    "            ccd_sci_bf = ccdp.flat_correct(ccd_sci_b, master_flatH_g)\n",
    "        ccd_sci_bfd = ccdp.subtract_dark(ccd_sci_bf, master_dark, exposure_time=10, exposure_unit=u.second)\n",
    "        ccd_sci_bfdg = ccdp.gain_correct(ccd_sci_bfd, ccd_gain)\n",
    "        # correction des différente images de callibrations\n",
    "        \n",
    "        ccd_sci_bfdg.write(path+path_dict[output[input.index(collection)]]+name, overwrite=True)\n",
    "        # sauvegarde images corrigées\n",
    "        \n",
    "        warnings.filterwarnings(\"default\")\n",
    "        # on réactive les warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1534ada6-7591-4c06-b5f2-5704350ba5ee",
   "metadata": {},
   "source": [
    "***Extraction***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af82691-faa7-423e-955a-ba23c846a6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour lister tous les fichiers .fit et .fits dans un dossier donné\n",
    "def list_fits_files(folder):\n",
    "    return [os.path.join(folder, f) for f in os.listdir(folder) if f.endswith(('.fit', '.fits'))]\n",
    "\n",
    "# Fonction pour calculer les distances entre les étoiles\n",
    "def calculate_distances(star_positions):\n",
    "    distances = []\n",
    "    for (x1, y1), (x2, y2) in combinations(star_positions, 2):\n",
    "        distance = np.sqrt((x2 - x1)**2 + (y2 - y1)**2)\n",
    "        distances.append(distance)\n",
    "    return distances\n",
    "\n",
    "data_path = ['baseline_23_t','baseline_24_t','obs_sec_r_t','obs_sec_g_t','obs_pri_r_t']\n",
    "\n",
    "for data_set in data_path:\n",
    "    # Initialisation des paramètres\n",
    "    folder_path = os.path.join(path, path_dict[data_set])\n",
    "    fits_files = list_fits_files(folder_path)\n",
    "    # ouverture des data set de fits\n",
    "    \n",
    "    num_stars_to_extract = 4\n",
    "    aperture_radius = 80\n",
    "    annulus_inner_radius = 130\n",
    "    annulus_outer_radius = 200\n",
    "    # initialisation des appeture, annulus et nombres d'étoiles d'extraction + l'étoiles d'étude\n",
    "    \n",
    "    intensity_data = []\n",
    "    normalized_intensities = []\n",
    "    target_intensities = []\n",
    "    reference_intensities = []\n",
    "    target_uncertainties = []\n",
    "    reference_uncertainties = []\n",
    "    normalized_uncertainties = []\n",
    "    observation_dates = []\n",
    "    filters_used = []\n",
    "    reference_distances = None\n",
    "    # Initialiser des listes pour stocker les résultats\n",
    "    \n",
    "    for fits_file in tqdm(fits_files, desc=\"Traitement des images FITS\"):\n",
    "        is_consistent = True\n",
    "        # variable détectant la consistence d'extraction du flux d'une étoile à une autres\n",
    "        \n",
    "        print(f\"Traitement du fichier : {fits_file}\")\n",
    "        \n",
    "        with fits.open(fits_file) as hdu:\n",
    "            header = hdu[0].header\n",
    "            date_obs = header.get('DATE-OBS', None)\n",
    "            filter_used = header.get('FILTER', 'unknown')\n",
    "            filters_used.append(filter_used)\n",
    "            # extraction des métadonnées du fichier\n",
    "    \n",
    "            image_data = CCDData(hdu[0].data, unit='adu')\n",
    "            read_noise = header.get('RDNOISE', 0)\n",
    "            bkg_error = np.std(image_data.data)\n",
    "            error_map = calc_total_error(image_data.data, bkg_error, read_noise)\n",
    "            # extraction de l'image et de l'erreur\n",
    "    \n",
    "        mean, median, std = np.mean(image_data.data), np.median(image_data.data), mad_std(image_data.data)\n",
    "        daofind = DAOStarFinder(fwhm=20.0, threshold=5.*std)\n",
    "        sources = daofind(image_data.data - median)\n",
    "        # Détection des étoiles\n",
    "    \n",
    "        if sources is None or len(sources) < num_stars_to_extract:\n",
    "            print(f\"Pas assez d'étoiles détectées dans {fits_file}\")\n",
    "            is_consistent = False\n",
    "            intensity_data.append([np.nan] * num_stars_to_extract)\n",
    "            continue\n",
    "            # on vérifie que le nombre d'étoiles détecté dans l'images est au minmum le nombres d'étoiles à détecter, si on ne détecte pas assez d'étoiles on saut l'images\n",
    "    \n",
    "        sorted_sources = sources[np.argsort(sources['flux'])[::-1]]\n",
    "        star_positions = np.array([(x, y) for x, y in zip(sorted_sources['xcentroid'], sorted_sources['ycentroid'])])\n",
    "        star_positions = star_positions[:num_stars_to_extract]\n",
    "        # extraction des position des 4 étoiles les plus brillantes de l'images\n",
    "    \n",
    "        apertures = CircularAperture(star_positions, r=aperture_radius)\n",
    "        annuli = CircularAnnulus(star_positions, r_in=annulus_inner_radius, r_out=annulus_outer_radius)\n",
    "        # initialisation des apertures et annulus\n",
    "    \n",
    "        current_distances = calculate_distances(star_positions)\n",
    "        # calcul de la distances entres les 4 premières étoiles\n",
    "    \n",
    "        if reference_distances is None:\n",
    "            reference_distances = current_distances\n",
    "            print(f\"Distances de référence initialisées pour {fits_file}: {reference_distances}\")\n",
    "            # initialisation des distance de référence, on suppose que les distance dans la première images sont correcte\n",
    "        \n",
    "        else:\n",
    "            distance_changes = [abs(current - reference) for current, reference in zip(current_distances, reference_distances)]\n",
    "            max_change = max(distance_changes)\n",
    "            if max_change > 10:\n",
    "                print(f\"Incohérence détectée dans {fits_file}\")\n",
    "                is_consistent = False\n",
    "                # si la différence de distance entre deux valeur des distances et marqué alors ça implique qu'une étoiles n'ai pas la bonne d'une images à une autres on saut l'image\n",
    "    \n",
    "        if is_consistent:\n",
    "            phot_table = aperture_photometry(image_data.data, apertures, error=error_map)\n",
    "            intensities = phot_table['aperture_sum'][:num_stars_to_extract]\n",
    "            errors = phot_table['aperture_sum_err'][:num_stars_to_extract]\n",
    "            # extraction de l'intensité et de l'erreur pour l'image importé\n",
    "        \n",
    "            if len(intensities) < num_stars_to_extract:\n",
    "                intensities = np.pad(intensities, (0, num_stars_to_extract - len(intensities)), constant_values=np.nan)\n",
    "                errors = np.pad(errors, (0, num_stars_to_extract - len(errors)), constant_values=np.nan)\n",
    "        \n",
    "            target_intensity = intensities[1]\n",
    "            target_uncertainty = errors[1]\n",
    "            reference_intensity = np.mean([intensities[0], intensities[2], intensities[3]])\n",
    "            reference_uncertainty = np.sqrt(np.sum(errors[[0, 2, 3]]**2)) / 3\n",
    "            # extraction des intensités et erreur\n",
    "            \n",
    "            if (np.min([intensities[0], intensities[2], intensities[3]])-mean)>100000:\n",
    "                # on vérifie que les étoiles minimales n'atteigne pas une limite minimale à partir de laquelles l'intensité sature\n",
    "    \n",
    "                if date_obs is not None:\n",
    "                    observation_dates.append(Time(date_obs).jd)\n",
    "            \n",
    "                target_intensities.append(target_intensity)\n",
    "                target_uncertainties.append(target_uncertainty)\n",
    "                reference_intensities.append(reference_intensity)\n",
    "                reference_uncertainties.append(reference_uncertainty)\n",
    "            \n",
    "                normalized_value = target_intensity / reference_intensity\n",
    "                normalized_uncertainty = normalized_value * np.sqrt((target_uncertainty / target_intensity)**2 + (reference_uncertainty / reference_intensity)**2)\n",
    "            \n",
    "                normalized_intensities.append(normalized_value)\n",
    "                normalized_uncertainties.append(normalized_uncertainty)\n",
    "                intensity_data.append(intensities)\n",
    "                # extraction des valeurs\n",
    "            \n",
    "                print(f\"Intensités extraites pour {fits_file}\")\n",
    "    \n",
    "        else:\n",
    "            print(f\"Incohérence des étoiles visée, l'intensité n'as pas été extraite pour {fits_file}\")\n",
    "    \n",
    "    intensity_data = np.array(intensity_data)\n",
    "    column_names = ['Étoile 1', 'RT And', 'Étoile 3', 'Étoile 4']\n",
    "    intensity_df = pd.DataFrame(intensity_data, columns=column_names)\n",
    "    # on ordonnes les intensité en fonction des étoiles\n",
    "    \n",
    "    # Écriture des résultats dans un fichier CSV\n",
    "    with open(folder_path + '_light_curve_data.csv', 'w', newline='') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile)\n",
    "        csvwriter.writerow(['observation_date', 'target_intensity', 'target_intensity_uncertainties', 'reference_intensity', \n",
    "                            'reference_intensity_uncertainties', 'normalized_intensity', 'normalized_intensity_uncertainties', 'filter'])\n",
    "        for i in range(len(observation_dates)):\n",
    "            csvwriter.writerow([observation_dates[i], \n",
    "                                target_intensities[i],\n",
    "                                target_uncertainties[i],\n",
    "                                reference_intensities[i], \n",
    "                                reference_uncertainties[i],\n",
    "                                normalized_intensities[i], \n",
    "                                normalized_uncertainties[i],\n",
    "                                filters_used[i]])\n",
    "    \n",
    "    # Tracer le graphique des intensités\n",
    "    plt.figure()\n",
    "    plt.plot(observation_dates, target_intensities, marker='o', linestyle=' ', color='red', label='Target Star Intensity')\n",
    "    plt.plot(observation_dates, reference_intensities, marker='o', linestyle=' ', color='blue', label='Reference Star Intensity')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.xlabel('Date of Observation (JD)')\n",
    "    plt.ylabel('Intensity')\n",
    "    plt.title(f'Light Curve of the Target Star (Filter: {filters_used[0]})')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(folder_path + '_light_curve.png', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    # Tracer la courbe de lumière normalisée\n",
    "    plt.figure()\n",
    "    plt.plot(observation_dates, normalized_intensities, marker='o', linestyle=' ', color='red', label='Normalized Light Curve')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.xlabel('Date of Observation (JD)')\n",
    "    plt.ylabel('Normalized Intensity')\n",
    "    plt.title(f'Normalized Light Curve of the Target Star (Filter: {filters_used[0]})')\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(folder_path + '_light_curve_normalised.png', dpi=300)\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
